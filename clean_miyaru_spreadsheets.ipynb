{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b03ca1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. Load the CSV file\n",
    "# NOTE: Make sure the file path is correct for your environment\n",
    "df = pd.read_csv(\"D:\\Documents\\SARA\\MIYARU\\citizen science\\miyaru cs apr25.csv\")\n",
    "\n",
    "# 2. Check the existing column names\n",
    "print(\"Old column names:\")\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b263f4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b54bb55",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = ['Submission ID', 'Last updated', 'Submission started', 'Status',\n",
    "       'Current step', 'Name',\n",
    "       'Affiliation',\n",
    "       'Email',\n",
    "       'Updates_required',\n",
    "       'Species',\n",
    "       'Number',\n",
    "       'Depth_range',\n",
    "       'Size',\n",
    "       'Behaviours',\n",
    "       'Injuries',\n",
    "       'Mating_scars',\n",
    "       'Notes',\n",
    "       'Media',\n",
    "       'Atoll', 'Island',\n",
    "       'Site_name',\n",
    "       'Coords',\n",
    "       'Habitat',\n",
    "       'Activity',\n",
    "       'Encounter_date',\n",
    "       'Start_time',\n",
    "       'Duration',\n",
    "       'Surface_temperature',\n",
    "       'Bottom_temperature',\n",
    "       'Visibility',\n",
    "       'Tide', 'Current_strength',\n",
    "       'Current_direction',\n",
    "       'Water_movement',\n",
    "       'N_people',\n",
    "       'N_Boats',\n",
    "       'Bait',\n",
    "       'Bait_type',\n",
    "       'Bait_composition',\n",
    "       'Bait_amount',\n",
    "       'Notes_2',\n",
    "       'Errors', 'Url', 'Network ID']\n",
    "\n",
    "# 4. Verify the columns have been renamed\n",
    "print(\"\\nNew column names:\")\n",
    "print(df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a97d561",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a2ee3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "###############################################################################\n",
    "# 1. DICTIONARIES OF ABBREVIATIONS\n",
    "###############################################################################\n",
    "species_to_abbr = {\n",
    "    \"Blacktip Reef Shark (Carcharhinus melanopterus)\": \"BT\",\n",
    "    \"Whitetip Reef Shark (Triaenodon obesus)\": \"WT\",\n",
    "    \"Grey Reef Shark (Carcharinus amblyrhynchos)\": \"Gr\",\n",
    "    \"Silvertip Shark (Carcharhinus albimarginatus)\": \"ST\",\n",
    "    \"Nurse Shark (Nebrius ferrugineus)\": \"Nu\",\n",
    "    \"Zebra Shark (Stegostoma fasciatum)\": \"Ze\",\n",
    "    \"Leopard/Zebra Shark (Stegostoma fasciatum)\": \"Ze\",\n",
    "    \"Spinner Shark (Carcharhinus brevipinna)\": \"Sp\",\n",
    "    \"Tiger Shark (Galeocerdo Cuvier)\": \"Ti\",\n",
    "    \"Bull Shark (Carcharhinus leucas)\": \"Bu\",\n",
    "    \"Lemon Shark (Negaprion acutidens)\": \"Le\",\n",
    "    \"Great Hammerhead Shark (Sphyrna mokarran)\": \"GH\",\n",
    "    \"Scalloped Hammerhead Shark (Sphyrna lewini)\": \"SH\",\n",
    "    \"Pelagic Thresher Shark (Alopias pelagicus)\": \"PT\",\n",
    "    \"Bigeye Thresher Shark (Alopias superciliosus)\": \"BET\",\n",
    "    \"Oceanic Whitetip Shark (Carcharhinus longimanus)\": \"OW\",\n",
    "    \"Shortfin Mako Shark (Isurus oxyrinchus)\": \"SM\",\n",
    "    \"Smalltooth Sand Tiger Shark (Odantaspis ferox)\": \"SS\",\n",
    "    \"Giant Guitarfish (Rhynchobatus djiddensis)\": \"GG\",\n",
    "    \"Bowmouth Guitarfish (Rhina ancylostoma)\": \"BG\",\n",
    "}\n",
    "\n",
    "atoll_to_abbr = {\n",
    "    \"Haa Alif\": \"HA\",\n",
    "    \"Haa Dhaal\": \"HDh\",\n",
    "    \"Shaviyani\": \"Sh\",\n",
    "    \"Noonu\": \"N\",\n",
    "    \"Lhavhiyani\": \"Lh\",\n",
    "    \"Raa\": \"R\",\n",
    "    \"Baa\": \"B\",\n",
    "    \"Kaafu\": \"K\",\n",
    "    \"Alif Alif\": \"AA\",\n",
    "    \"Alif Dhaal\": \"ADh\",\n",
    "    \"Vaavu\": \"V\",\n",
    "    \"Dhaalu\": \"Dh\",\n",
    "    \"Meemu\": \"M\",\n",
    "    \"Thaa\": \"T\",\n",
    "    \"Laamu\": \"L\",\n",
    "    \"Gaaf Alif\": \"GA\",\n",
    "    \"Gaaf Dhaal\": \"GDh\",\n",
    "    \"Gnaviyani (Fuvahmulah)\": \"Gn\",\n",
    "    \"Seenu (Addu)\": \"S\",\n",
    "}\n",
    "\n",
    "##########################################################################\n",
    "# 2) Convert Encounter_date to datetime and create yyyymmdd column\n",
    "##########################################################################\n",
    "df[\"Encounter_date\"] = pd.to_datetime(df[\"Encounter_date\"], errors='coerce')\n",
    "df[\"Date_yyyymmdd\"] = df[\"Encounter_date\"].dt.strftime(\"%Y%m%d\")\n",
    "\n",
    "##########################################################################\n",
    "# 3) Map species and atoll columns to abbreviations\n",
    "##########################################################################\n",
    "df[\"Species_Abbr\"] = df[\"Species\"].map(species_to_abbr)\n",
    "df[\"Atoll_Abbr\"] = df[\"Atoll\"].map(atoll_to_abbr)\n",
    "\n",
    "##########################################################################\n",
    "# 4) Build the grouping-based counter\n",
    "#    For each unique (Species, Atoll, Encounter_date), \n",
    "#    assign an incrementing counter: 1, 2, 3...\n",
    "##########################################################################\n",
    "# Drop any rows lacking Species, Atoll, or Encounter_date\n",
    "df.dropna(subset=[\"Species\", \"Atoll\", \"Encounter_date\"], inplace=True)\n",
    "\n",
    "# Now group and cumcount\n",
    "df[\"n\"] = (\n",
    "    df.groupby([\"Species\", \"Atoll\", \"Encounter_date\"])[\"Encounter_date\"]\n",
    "    .cumcount()\n",
    "    + 1\n",
    ")\n",
    "\n",
    "# This will now work without error\n",
    "df[\"n\"] = df[\"n\"].astype(int)\n",
    "##########################################################################\n",
    "# 5) Construct the Unique_ID column\n",
    "##########################################################################\n",
    "df[\"Unique_ID\"] = (\n",
    "    df[\"Species_Abbr\"].astype(str)\n",
    "    + \"_\"\n",
    "    + df[\"Atoll_Abbr\"].astype(str)\n",
    "    + \"_\"\n",
    "    + df[\"Date_yyyymmdd\"].astype(str)\n",
    "    + \"_\"\n",
    "    + df[\"n\"].astype(str)\n",
    ")\n",
    "\n",
    "# (Optional) See how it looks\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3213423",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. Load the CSV file\n",
    "# NOTE: Make sure the file path is correct for your environment\n",
    "df2 = pd.read_csv(\"/Volumes/AugustMV25B/miyaru cs apr23-apr24.csv\")\n",
    "\n",
    "# 2. Check the existing column names\n",
    "print(\"Old column names:\")\n",
    "print(df2.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82100b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
